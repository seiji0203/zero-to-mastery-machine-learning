# 学習資料 - リカレントニューラルネットワーク - 
## 概要
リカレントニューラルネットワークを学習します。

## 目標
自然言語処理<br>
- [ ] 00, Word2Vec
- [ ] 01, RNNとは
- [ ] 02, BPTT(Backpropagation Through Time)
- [ ] 03, ELMo
- [ ] 04, LSTM
- [ ] 05, GRU
- [ ] 06, Seq2Seq
- [ ] 07, Attention
- [ ] 08, Transformer
- [ ] 09, BERT
- [ ] 10, GPT

## 学習方法
以下の参考資料を使って目標を達成します。

## 学習項
- [RNN(リカレントニューラルネットワーク)の概要とPython実装方法を分かりやすく解説！](https://toukei-lab.com/rnn)
- [Word2Vecを理解する](https://qiita.com/g-k/items/69afa87c73654af49d36)
- [深層学習 再帰的ニューラルネットワーク](https://zenn.dev/takasaki/articles/ce60ffcd6f736a)
- [【論文解説】ELMoを理解する](https://data-analytics.fun/2020/07/13/understanding-elmo/)
- [〈機械学習基礎〉数式なし！ LSTM・GRU超入門](https://agirobots.com/lstmgruentrance-noformula/)
- [Sequence To Sequence (Seq2Seq)](https://blog.octopt.com/sequence-to-sequence/)
- [【深層学習】図で理解するAttention機構](https://qiita.com/ps010/items/0bb2931b666fa602d0fc)
- [深層学習界の大前提Transformerの論文解説！](https://qiita.com/omiita/items/07e69aef6c156d23c538)
- [自然言語処理の王様「BERT」の論文を徹底解説](https://qiita.com/omiita/items/72998858efc19a368e50)
- [【論文解説】OpenAI 「GPT-3」を理解する](https://data-analytics.fun/2020/12/07/openai-gpt3/)

参考書籍の解説
- [『ゼロから作るDeep Learning 2』の学習ノート：記事一覧](https://www.anarchive-beta.com/entry/2020/08/28/185900)
