# モデルの評価
- ホールドアウト法
- LOOCV
- k分割交差検証
- グリッドサーチ
- バイアスとバリアンス
- 汎化性能
- 過学習(overfitting)と学習不足(underfitting)

## web
- [(超重要)過学習と汎化性能を理解する(hold-out法を解説)【機械学習入門7】](https://datawokagaku.com/holdout/)
- [LOOCVについて解説&Pythonで実装する【機械学習入門8】](https://datawokagaku.com/loocv/)
- [k-Fold Cross Validation(交差検証)を解説する【機械学習入門9】](https://datawokagaku.com/kfoldcv/)
- [回帰モデルの評価指標を一挙に解説(MSE, RMSE, MAE, R-Squared等)【機械学習入門10】](https://datawokagaku.com/reg_metrics/)
- [超重要！Bias-Variance Tradeoffを完全に理解する【機械学習入門12】](https://datawokagaku.com/bias_variance_tradeoff/)

- [ホールドアウト法・交差検証](https://aiacademy.jp/texts/show/?id=299&context=subject-metrics)
- [ホールドアウト検証とK分割交差検証(K-foldクロスバリデーション)](https://di-acc2.com/analytics/ai/6498/)
- [交差検証（Python実装）を徹底解説！図解・サンプル実装コードあり](https://www.codexa.net/cross_validation/)
- [グリッドサーチ](https://aiacademy.jp/texts/show/?id=542&context=subject-metrics)
- [バイアスとバリアンス（偏りと分散）のトレードオフ（Bias-Variance Tradeoff）とは？](https://atmarkit.itmedia.co.jp/ait/articles/2009/09/news025.html)
